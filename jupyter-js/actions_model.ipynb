{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML imports\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "\n",
    "# np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_csv_files = []\n",
    "path = r'C:\\Users\\conno\\Desktop\\Pastebles\\data'\n",
    "\n",
    "# Will grab any subfolders from path and their csv files\n",
    "for root,dirs,files in os.walk(path):\n",
    "    for filename in files:\n",
    "        if filename.endswith(\".csv\"):\n",
    "            all_csv_files.append(root+'\\\\'+filename)\n",
    "\n",
    "X_data = []\n",
    "y_data = []\n",
    "for filename in all_csv_files:\n",
    "    match  = re.findall('[a-zA-Z]+(?=_[0-9]+_data)', str(filename))\n",
    "    y = (''.join(match))\n",
    "    # Reads individual csv files\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=',')\n",
    "        for index, row in enumerate(spamreader):\n",
    "            if(index != 0):\n",
    "                y_data.append(y)\n",
    "                # Remove arrival time (column 0)\n",
    "                add = row[1:8]\n",
    "                X_data.append(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "# Train new model\n",
    "def train_new_model_new(path, model):\n",
    "    \n",
    "    all_csv_files = []\n",
    "    path = r'C:\\Users\\conno\\Desktop\\Pastebles\\data'\n",
    "\n",
    "    # Will grab any subfolders from path and their csv files\n",
    "    for root,dirs,files in os.walk(path):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".csv\"):\n",
    "                all_csv_files.append(root+'\\\\'+filename)\n",
    "\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    for filename in all_csv_files:\n",
    "        match  = re.findall('[a-zA-Z]+(?=_[0-9]+_data)', str(filename))\n",
    "        y = (''.join(match))\n",
    "        # Reads individual csv files\n",
    "        with open(filename, newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile, delimiter=',')\n",
    "            for index, row in enumerate(spamreader):\n",
    "                if(index != 0):\n",
    "                    y_data.append(y)\n",
    "                    # Remove arrival time (column 0)\n",
    "                    add = row[1:8]\n",
    "                    X_data.append(add)\n",
    "\n",
    "\n",
    "    # Changes target from string to numeric\n",
    "    le = LabelEncoder().fit(y_data)\n",
    "    y = le.transform(y_data)\n",
    "\n",
    "    # Sets the X data\n",
    "    X = np.array(X_data)\n",
    "    \n",
    "    # Splits data into training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20) # random_state=42\n",
    "    \n",
    "    # Pipeline from data pre-processing to model training\n",
    "    pipe_model = make_pipeline(StandardScaler(), model)\n",
    "    pipe_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Model predictions\n",
    "    y_pred = pipe_model.predict(X_test)\n",
    "\n",
    "    accuracy = pipe_model.score(X_test, y_test)\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    # Save model\n",
    "    #joblib.dump(pipe_model, 'actions_model.pkl')\n",
    "\n",
    "    print(\"Model:\", model, \"\\nAccuracy:\", accuracy, \"\\nRecall:\", recall, \"\\nPrecision:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "# Train new model\n",
    "def train_new_model(path, model):\n",
    "    \n",
    "    # Holder list\n",
    "    li = []\n",
    "\n",
    "    # Regex changes the target class creation\n",
    "    # 'CORRECT|WRONG|[a-zA-Z]+(?=_[0-9]+_data)|(?<=IR_[0-9]_)[a-zA-Z]+'\n",
    "    \n",
    "    # Will grab any subfolders from path and their csv files\n",
    "\n",
    "    for filename in Path(path).rglob('*.csv'):\n",
    "        # Reads individual csv files\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        # Matches specifics from the filename using regex (subject to change depending on filenaming convention)   \n",
    "        match  = re.findall('[a-zA-Z]+(?=_[0-9]+_data)', str(filename))\n",
    "        y = (''.join(match))\n",
    "        # Adds target column for classification\n",
    "        df['y'] = y\n",
    "        # Appends the dataframe to the list\n",
    "        li.append(df)\n",
    "\n",
    "    # Concats all data into one dataframe for training/testing\n",
    "    frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "    # Target column is y\n",
    "    y_string = frame['y']\n",
    "\n",
    "    # Changes target from string to numeric\n",
    "    le = LabelEncoder().fit(y_string.ravel())\n",
    "    y = le.transform(y_string.ravel())\n",
    "    print(le.classes_)\n",
    "    print(le.transform(le.classes_))\n",
    "    # Sets the X data\n",
    "    X = frame.drop(['y','arrival_time'],axis=1).to_numpy()\n",
    "    \n",
    "    # Splits data into training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20) # random_state=42\n",
    "    \n",
    "    # Pipeline from data pre-processing to model training\n",
    "    pipe_model = make_pipeline(StandardScaler(), model)\n",
    "    pipe_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Model predictions\n",
    "    y_pred = pipe_model.predict(X_test)\n",
    "\n",
    "    accuracy = pipe_model.score(X_test, y_test)\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    # Save model\n",
    "    #joblib.dump(pipe_model, 'actions_model.pkl')\n",
    "\n",
    "    print(\"Model:\", model, \"\\nAccuracy:\", accuracy, \"\\nRecall:\", recall, \"\\nPrecision:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BicepCurls' 'Posture' 'SideLunges' 'Sitting' 'Squats' 'Standing']\n",
      "[0 1 2 3 4 5]\n",
      "Model: RandomForestClassifier() \n",
      "Accuracy: 0.9244621513944223 \n",
      "Recall: 0.9324816473616228 \n",
      "Precision: 0.9321683500317951\n"
     ]
    }
   ],
   "source": [
    "train_new_model(r'/home/connor/Desktop/Pastebles/data', RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ff6a3cd737f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_new_model_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/home/connor/Desktop/Pastebles/data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-46460c2f753d>\u001b[0m in \u001b[0;36mtrain_new_model_new\u001b[0;34m(path, model)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# Splits data into training and testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# random_state=42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Pipeline from data pre-processing to model training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2174\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2175\u001b[0;31m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[0m\u001b[1;32m   2176\u001b[0m                                               default_test_size=0.25)\n\u001b[1;32m   2177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1856\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1857\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1858\u001b[0m             \u001b[0;34m'With n_samples={}, test_size={} and train_size={}, the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1859\u001b[0m             \u001b[0;34m'resulting train set will be empty. Adjust any of the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "train_new_model_new(r'/home/connor/Desktop/Pastebles/data', RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstracted funtion for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Options are: \n",
    "# DecisionTreeClassifier()\n",
    "# RandomForestClassifier()\n",
    "# SVC()\n",
    "\n",
    "# Path example:\n",
    "# r'C:\\Users\\conno\\Desktop\\Pastebles\\data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-266c5bdff307>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example of training a new model with its associted testing score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_new_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'C:\\Users\\conno\\Desktop\\Pastebles\\data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-1032cd437fc7>\u001b[0m in \u001b[0;36mtrain_new_model\u001b[0;34m(path, model)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Concats all data into one dataframe for training/testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Target column is y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \"\"\"\n\u001b[0;32m--> 285\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# Example of training a new model with its associted testing score\n",
    "train_new_model(r'/home/connor/Desktop/Pastebles/data', RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'actions_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4d72b2b2a5b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'actions_model.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'actions_model.pkl'"
     ]
    }
   ],
   "source": [
    "loaded_model = joblib.load('actions_model.pkl')\n",
    "loaded_model.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to data directory\n",
    "\n",
    "# Change to desired path\n",
    "path = r'C:\\Users\\conno\\Desktop\\Pastebles\\data'\n",
    "# Will grab any subfolders from path and their csv files\n",
    "all_files = glob.glob(path + \"/*/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reads in all data and adds target column for classification\n",
    "\n",
    "# Holder list\n",
    "li = []\n",
    "\n",
    "# Regex changes the target class creation\n",
    "# 'CORRECT|WRONG|[a-zA-Z]+(?=_[0-9]+_data)|(?<=IR_[0-9]_)[a-zA-Z]+'\n",
    "\n",
    "for filename in all_files:\n",
    "    # Reads individual csv files\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    # Matches specifics from the filename using regex (subject to change depending on filenaming convention)    \n",
    "    match  = re.findall('[a-zA-Z]+(?=_[0-9]+_data)', filename)\n",
    "    y = (''.join(match))\n",
    "    # Adds target column for classification\n",
    "    df['y'] = y\n",
    "    # Appends the dataframe to the list\n",
    "    li.append(df)\n",
    "\n",
    "# Concats all data into one dataframe for training/testing\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target column is y\n",
    "y_string = frame['y']\n",
    "\n",
    "# Changes target from string to numeric\n",
    "le = LabelEncoder().fit(y_string.ravel())\n",
    "y = le.transform(y_string.ravel())\n",
    "\n",
    "# Sets the X data\n",
    "X = frame.drop(['y','arrival_time'],axis=1).to_numpy()\n",
    "\n",
    "# Splits data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20) # random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching for best parameters\n",
    "# parameters = {'criterion':('gini', 'entropy'), 'n_estimators':[100, 200, 300, 400, 500]}\n",
    "\n",
    "# clf = GridSearchCV(RandomForestClassifier(), parameters)\n",
    "# clf = clf.fit(X_train, y_train)\n",
    "# clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_dc = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "# clf_dc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9839043824701196 \n",
      "Recall: 0.9857151033847505 \n",
      "Precision: 0.9858603945648308\n"
     ]
    }
   ],
   "source": [
    "# Loaded model from the train_model function\n",
    "loaded_model = joblib.load('actions_model.pkl')\n",
    "\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "accuracy = loaded_model.score(X_test, y_test)\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "print(\"Accuracy:\", accuracy, \"\\nRecall:\", recall, \"\\nPrecision:\", precision)\n",
    "\n",
    "# The accuracy is so high because the train test split is different from the trained model. \n",
    "# Testing data here could have been used as training data when the model was trained reslulting in a higher accuracy.\n",
    "# This is not a problem for actual application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9231474103585657 \n",
      "Recall: 0.9326212137433462 \n",
      "Precision: 0.9320199194925465\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test) \n",
    "\n",
    "clf_rfc = RandomForestClassifier().fit(X_train, y_train)\n",
    "y_pred = clf_rfc.predict(X_test)\n",
    "\n",
    "accuracy = clf_rfc.score(X_test, y_test)\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"Accuracy:\", accuracy, \"\\nRecall:\", recall, \"\\nPrecision:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posture - Accuracy: 0.9963304971974677\n",
      "BicepCurls - Accuracy: 0.9873422712933754\n",
      "SideLunges - Accuracy: 0.9721867007672634\n",
      "Sitting - Accuracy: 0.9968770019218449\n",
      "Squats - Accuracy: 0.9736987818383167\n",
      "Standing - Accuracy: 0.9931430393876575\n",
      "Average for entire dataset:  0.9865963820676543\n"
     ]
    }
   ],
   "source": [
    "# Scoring indivdual actions for the whole dataset\n",
    "\n",
    "actions = frame['y'].unique()\n",
    "scores_entire = []\n",
    "\n",
    "for action in actions:\n",
    "    # Get the data and select only the wanted action for scoring\n",
    "    data = frame.loc[frame['y'] == action]\n",
    "    # Get the y data\n",
    "    y_string = data['y']\n",
    "    # Convert the y to numeric classes\n",
    "    y_data = le.transform(y_string.ravel())\n",
    "    # Get the X data\n",
    "    X_data = data.drop(['y','arrival_time'],axis=1).to_numpy()\n",
    "    \n",
    "    accuracy = clf_rfc.score(X_data, y_data)\n",
    "    scores_entire.append(accuracy)\n",
    "    print(action +\" - \"+ \"Accuracy:\", accuracy)\n",
    "    \n",
    "# Not quite and exact average because different actions may have more data points, but it should be really close.\n",
    "print(\"Average for entire dataset: \", np.mean(scores_entire, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posture - Accuracy: 0.9818977521384523\n",
      "BicepCurls - Accuracy: 0.9364608076009501\n",
      "SideLunges - Accuracy: 0.8609668397922493\n",
      "Sitting - Accuracy: 0.9841784989858012\n",
      "Squats - Accuracy: 0.8677669516802545\n",
      "Standing - Accuracy: 0.9658865529551766\n",
      "Average for testing dataset:  0.9328595671921475\n"
     ]
    }
   ],
   "source": [
    "# Scoring indivdual actions for the testing dataset\n",
    "\n",
    "actions = frame['y'].unique()\n",
    "scores_testing = []\n",
    "\n",
    "for action in actions:\n",
    "    # Get y testing data\n",
    "    y_frame = pd.DataFrame(le.inverse_transform(y_test))\n",
    "    # Select only the wanted action for scoring\n",
    "    y_string = y_frame.where(y_frame == action).dropna()\n",
    "    # Get X testing data from the corresponding y indecies\n",
    "    X_data = X_test[y_string.index]\n",
    "    # Convert the y data back to numeric classes\n",
    "    y_data = le.transform(y_string.to_numpy().ravel())\n",
    "    # Reset y index (not needed currently)\n",
    "    # y_data = y_data.reset_index(drop=True)\n",
    "    \n",
    "    accuracy = clf_rfc.score(X_data, y_data)\n",
    "    scores_testing.append(accuracy)\n",
    "    print(action +\" - \"+ \"Accuracy:\", accuracy)\n",
    "\n",
    "# Not quite and exact average because different actions may have more data points, but it should be really close.\n",
    "print(\"Average for testing dataset: \", np.mean(scores_testing, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTreeClassifier() \n",
      "Accuracy: 0.8654581673306773 \n",
      "Recall: 0.8827407774427171 \n",
      "Precision: 0.880705116506292\n"
     ]
    }
   ],
   "source": [
    "# Function abstraction\n",
    "train_new_model(r'C:\\Users\\conno\\Desktop\\Pastebles\\data', DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: ['Squats'] \n",
      "Actual: ['SideLunges']\n"
     ]
    }
   ],
   "source": [
    "# Manually testing individual points\n",
    "\n",
    "index = 102\n",
    "x_pred = frame.drop(['arrival_time', \"y\"],axis=1).iloc[index].to_numpy().reshape(1,-1)\n",
    "x_pred = X_test[index].reshape(1, -1)\n",
    "y_pred = y_test[index].ravel()\n",
    "\n",
    "out = clf_rfc.predict(x_pred)\n",
    "# list(le.inverse_transform(out))\n",
    "# list(le.inverse_transform(y_test[0].ravel()))\n",
    "\n",
    "print(\"Predicted:\", le.inverse_transform(out), \"\\nActual:\",le.inverse_transform(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Holder list\n",
    "li = []\n",
    "\n",
    "# Regex changes the target class creation\n",
    "# 'CORRECT|WRONG|[a-zA-Z]+(?=_[0-9]+_data)|(?<=IR_[0-9]_)[a-zA-Z]+'\n",
    "\n",
    "# Will grab any subfolders from path and their csv files\n",
    "\n",
    "for filename in Path(r'C:\\Users\\conno\\Desktop\\Pastebles\\data').rglob('*.csv'):\n",
    "    # Reads individual csv files\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    # Matches specifics from the filename using regex (subject to change depending on filenaming convention)   \n",
    "    match  = re.findall('[a-zA-Z]+(?=_[0-9]+_data)', str(filename))\n",
    "    y = (''.join(match))\n",
    "    # Adds target column for classification\n",
    "    df['y'] = y\n",
    "    # Appends the dataframe to the list\n",
    "    li.append(df)\n",
    "\n",
    "# Concats all data into one dataframe for training/testing\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "frame = frame.drop(['arrival_time'],axis=1)\n",
    "\n",
    "msk = np.random.rand(len(frame)) < 0.8\n",
    "train = frame[msk]\n",
    "test = frame[~msk]\n",
    "\n",
    "train.to_csv('training.csv', index = False);\n",
    "test.to_csv('testing.csv', index = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>rot_x</th>\n",
       "      <th>rot_y</th>\n",
       "      <th>rot_z</th>\n",
       "      <th>ir_dist</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-22 18:38:26.834683</td>\n",
       "      <td>0.960205</td>\n",
       "      <td>0.399536</td>\n",
       "      <td>0.059570</td>\n",
       "      <td>-9.033203</td>\n",
       "      <td>-3.967285</td>\n",
       "      <td>-7.446289</td>\n",
       "      <td>12</td>\n",
       "      <td>Posture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-22 18:38:26.896499</td>\n",
       "      <td>1.013672</td>\n",
       "      <td>0.388306</td>\n",
       "      <td>0.128784</td>\n",
       "      <td>23.559570</td>\n",
       "      <td>16.479492</td>\n",
       "      <td>-9.887695</td>\n",
       "      <td>13</td>\n",
       "      <td>Posture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-22 18:38:26.958310</td>\n",
       "      <td>0.945923</td>\n",
       "      <td>0.352295</td>\n",
       "      <td>0.144043</td>\n",
       "      <td>56.823730</td>\n",
       "      <td>13.916016</td>\n",
       "      <td>-2.319336</td>\n",
       "      <td>12</td>\n",
       "      <td>Posture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-22 18:38:27.019907</td>\n",
       "      <td>0.907959</td>\n",
       "      <td>0.367676</td>\n",
       "      <td>0.103760</td>\n",
       "      <td>31.616211</td>\n",
       "      <td>-7.751465</td>\n",
       "      <td>-0.183105</td>\n",
       "      <td>12</td>\n",
       "      <td>Posture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-22 18:38:27.081720</td>\n",
       "      <td>0.886719</td>\n",
       "      <td>0.404663</td>\n",
       "      <td>0.116699</td>\n",
       "      <td>-1.953125</td>\n",
       "      <td>-26.245117</td>\n",
       "      <td>-2.319336</td>\n",
       "      <td>12</td>\n",
       "      <td>Posture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125492</th>\n",
       "      <td>2021-06-30 16:11:56.917636</td>\n",
       "      <td>0.973633</td>\n",
       "      <td>0.137695</td>\n",
       "      <td>0.215698</td>\n",
       "      <td>-1.098633</td>\n",
       "      <td>-7.141113</td>\n",
       "      <td>-1.098633</td>\n",
       "      <td>114</td>\n",
       "      <td>Squats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125493</th>\n",
       "      <td>2021-06-30 16:11:56.980679</td>\n",
       "      <td>0.977783</td>\n",
       "      <td>0.142212</td>\n",
       "      <td>0.211060</td>\n",
       "      <td>-0.366211</td>\n",
       "      <td>-7.324219</td>\n",
       "      <td>-1.342773</td>\n",
       "      <td>114</td>\n",
       "      <td>Squats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125494</th>\n",
       "      <td>2021-06-30 16:11:57.041932</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.135132</td>\n",
       "      <td>0.210815</td>\n",
       "      <td>-1.037598</td>\n",
       "      <td>-7.873535</td>\n",
       "      <td>-1.220703</td>\n",
       "      <td>114</td>\n",
       "      <td>Squats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125495</th>\n",
       "      <td>2021-06-30 16:11:57.103245</td>\n",
       "      <td>0.988770</td>\n",
       "      <td>0.135742</td>\n",
       "      <td>0.209595</td>\n",
       "      <td>-2.746582</td>\n",
       "      <td>-9.277344</td>\n",
       "      <td>-1.525879</td>\n",
       "      <td>124</td>\n",
       "      <td>Squats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125496</th>\n",
       "      <td>2021-06-30 16:11:57.166535</td>\n",
       "      <td>0.989624</td>\n",
       "      <td>0.130615</td>\n",
       "      <td>0.218628</td>\n",
       "      <td>-4.699707</td>\n",
       "      <td>-10.070801</td>\n",
       "      <td>-1.342773</td>\n",
       "      <td>124</td>\n",
       "      <td>Squats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125497 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      arrival_time     acc_x     acc_y     acc_z      rot_x  \\\n",
       "0       2021-06-22 18:38:26.834683  0.960205  0.399536  0.059570  -9.033203   \n",
       "1       2021-06-22 18:38:26.896499  1.013672  0.388306  0.128784  23.559570   \n",
       "2       2021-06-22 18:38:26.958310  0.945923  0.352295  0.144043  56.823730   \n",
       "3       2021-06-22 18:38:27.019907  0.907959  0.367676  0.103760  31.616211   \n",
       "4       2021-06-22 18:38:27.081720  0.886719  0.404663  0.116699  -1.953125   \n",
       "...                            ...       ...       ...       ...        ...   \n",
       "125492  2021-06-30 16:11:56.917636  0.973633  0.137695  0.215698  -1.098633   \n",
       "125493  2021-06-30 16:11:56.980679  0.977783  0.142212  0.211060  -0.366211   \n",
       "125494  2021-06-30 16:11:57.041932  0.984375  0.135132  0.210815  -1.037598   \n",
       "125495  2021-06-30 16:11:57.103245  0.988770  0.135742  0.209595  -2.746582   \n",
       "125496  2021-06-30 16:11:57.166535  0.989624  0.130615  0.218628  -4.699707   \n",
       "\n",
       "            rot_y     rot_z  ir_dist        y  \n",
       "0       -3.967285 -7.446289       12  Posture  \n",
       "1       16.479492 -9.887695       13  Posture  \n",
       "2       13.916016 -2.319336       12  Posture  \n",
       "3       -7.751465 -0.183105       12  Posture  \n",
       "4      -26.245117 -2.319336       12  Posture  \n",
       "...           ...       ...      ...      ...  \n",
       "125492  -7.141113 -1.098633      114   Squats  \n",
       "125493  -7.324219 -1.342773      114   Squats  \n",
       "125494  -7.873535 -1.220703      114   Squats  \n",
       "125495  -9.277344 -1.525879      124   Squats  \n",
       "125496 -10.070801 -1.342773      124   Squats  \n",
       "\n",
       "[125497 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pipeline from data pre-processing to model training\n",
    "pipe_model = make_pipeline(StandardScaler(), model)\n",
    "pipe_model.fit(X_train, y_train)\n",
    "\n",
    "# Model predictions\n",
    "y_pred = pipe_model.predict(X_test)\n",
    "\n",
    "accuracy = pipe_model.score(X_test, y_test)\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Save model\n",
    "#joblib.dump(pipe_model, 'actions_model.pkl')\n",
    "\n",
    "print(\"Model:\", model, \"\\nAccuracy:\", accuracy, \"\\nRecall:\", recall, \"\\nPrecision:\", precision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
