{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML imports\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "\n",
    "# np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "# Train new model\n",
    "def train_new_model(path, model):\n",
    "    \n",
    "    # Holder list\n",
    "    li = []\n",
    "\n",
    "    # Regex changes the target class creation\n",
    "    # 'CORRECT|WRONG|[a-zA-Z]+(?=_[0-9]+_data)|(?<=IR_[0-9]_)[a-zA-Z]+'\n",
    "    \n",
    "    # Will grab any subfolders from path and their csv files\n",
    "\n",
    "    for filename in Path(path).rglob('*.csv'):\n",
    "        # Reads individual csv files\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        # Matches specifics from the filename using regex (subject to change depending on filenaming convention)   \n",
    "        match  = re.findall('[a-zA-Z]+(?=_[0-9]+_data)', str(filename))\n",
    "        y = (''.join(match))\n",
    "        # Adds target column for classification\n",
    "        df['y'] = y\n",
    "        # Appends the dataframe to the list\n",
    "        li.append(df)\n",
    "\n",
    "    # Concats all data into one dataframe for training/testing\n",
    "    frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "    # Target column is y\n",
    "    y_string = frame['y']\n",
    "\n",
    "    # Changes target from string to numeric\n",
    "    le = LabelEncoder().fit(y_string.ravel())\n",
    "    y = le.transform(y_string.ravel())\n",
    "\n",
    "    # Sets the X data\n",
    "    X = frame.drop(['y','arrival_time'],axis=1).to_numpy()\n",
    "    \n",
    "    # Splits data into training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20) # random_state=42\n",
    "    \n",
    "    # Pipeline from data pre-processing to model training\n",
    "    pipe_model = make_pipeline(StandardScaler(), model)\n",
    "    pipe_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Model predictions\n",
    "    y_pred = pipe_model.predict(X_test)\n",
    "\n",
    "    accuracy = pipe_model.score(X_test, y_test)\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(pipe_model, 'actions_model.pkl')\n",
    "\n",
    "    print(\"Model:\", model, \"\\nAccuracy:\", accuracy, \"\\nRecall:\", recall, \"\\nPrecision:\", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstracted funtion for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Options are: \n",
    "# DecisionTreeClassifier()\n",
    "# RandomForestClassifier()\n",
    "# SVC()\n",
    "\n",
    "# Path example:\n",
    "# r'C:\\Users\\conno\\Desktop\\Pastebles\\data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier() \n",
      "Accuracy: 0.9252191235059761 \n",
      "Recall: 0.9338279722751749 \n",
      "Precision: 0.9340218456554473\n"
     ]
    }
   ],
   "source": [
    "# Example of training a new model with its associted testing score\n",
    "train_new_model(r'C:\\Users\\conno\\Desktop\\Pastebles\\data', RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to data directory\n",
    "\n",
    "# Change to desired path\n",
    "path = r'C:\\Users\\conno\\Desktop\\Pastebles\\data'\n",
    "# Will grab any subfolders from path and their csv files\n",
    "all_files = glob.glob(path + \"/*/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reads in all data and adds target column for classification\n",
    "\n",
    "# Holder list\n",
    "li = []\n",
    "\n",
    "# Regex changes the target class creation\n",
    "# 'CORRECT|WRONG|[a-zA-Z]+(?=_[0-9]+_data)|(?<=IR_[0-9]_)[a-zA-Z]+'\n",
    "\n",
    "for filename in all_files:\n",
    "    # Reads individual csv files\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    # Matches specifics from the filename using regex (subject to change depending on filenaming convention)    \n",
    "    match  = re.findall('[a-zA-Z]+(?=_[0-9]+_data)', filename)\n",
    "    y = (''.join(match))\n",
    "    # Adds target column for classification\n",
    "    df['y'] = y\n",
    "    # Appends the dataframe to the list\n",
    "    li.append(df)\n",
    "\n",
    "# Concats all data into one dataframe for training/testing\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target column is y\n",
    "y_string = frame['y']\n",
    "\n",
    "# Changes target from string to numeric\n",
    "le = LabelEncoder().fit(y_string.ravel())\n",
    "y = le.transform(y_string.ravel())\n",
    "\n",
    "# Sets the X data\n",
    "X = frame.drop(['y','arrival_time'],axis=1).to_numpy()\n",
    "\n",
    "# Splits data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20) # random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching for best parameters\n",
    "# parameters = {'criterion':('gini', 'entropy'), 'n_estimators':[100, 200, 300, 400, 500]}\n",
    "\n",
    "# clf = GridSearchCV(RandomForestClassifier(), parameters)\n",
    "# clf = clf.fit(X_train, y_train)\n",
    "# clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_dc = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "# clf_dc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9839043824701196 \n",
      "Recall: 0.9857151033847505 \n",
      "Precision: 0.9858603945648308\n"
     ]
    }
   ],
   "source": [
    "# Loaded model from the train_model function\n",
    "loaded_model = joblib.load('actions_model.pkl')\n",
    "\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "accuracy = loaded_model.score(X_test, y_test)\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "print(\"Accuracy:\", accuracy, \"\\nRecall:\", recall, \"\\nPrecision:\", precision)\n",
    "\n",
    "# The accuracy is so high because the train test split is different from the trained model. \n",
    "# Testing data here could have been used as training data when the model was trained reslulting in a higher accuracy.\n",
    "# This is not a problem for actual application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9231474103585657 \n",
      "Recall: 0.9326212137433462 \n",
      "Precision: 0.9320199194925465\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test) \n",
    "\n",
    "clf_rfc = RandomForestClassifier().fit(X_train, y_train)\n",
    "y_pred = clf_rfc.predict(X_test)\n",
    "\n",
    "accuracy = clf_rfc.score(X_test, y_test)\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"Accuracy:\", accuracy, \"\\nRecall:\", recall, \"\\nPrecision:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posture - Accuracy: 0.9963304971974677\n",
      "BicepCurls - Accuracy: 0.9873422712933754\n",
      "SideLunges - Accuracy: 0.9721867007672634\n",
      "Sitting - Accuracy: 0.9968770019218449\n",
      "Squats - Accuracy: 0.9736987818383167\n",
      "Standing - Accuracy: 0.9931430393876575\n",
      "Average for entire dataset:  0.9865963820676543\n"
     ]
    }
   ],
   "source": [
    "# Scoring indivdual actions for the whole dataset\n",
    "\n",
    "actions = frame['y'].unique()\n",
    "scores_entire = []\n",
    "\n",
    "for action in actions:\n",
    "    # Get the data and select only the wanted action for scoring\n",
    "    data = frame.loc[frame['y'] == action]\n",
    "    # Get the y data\n",
    "    y_string = data['y']\n",
    "    # Convert the y to numeric classes\n",
    "    y_data = le.transform(y_string.ravel())\n",
    "    # Get the X data\n",
    "    X_data = data.drop(['y','arrival_time'],axis=1).to_numpy()\n",
    "    \n",
    "    accuracy = clf_rfc.score(X_data, y_data)\n",
    "    scores_entire.append(accuracy)\n",
    "    print(action +\" - \"+ \"Accuracy:\", accuracy)\n",
    "    \n",
    "# Not quite and exact average because different actions may have more data points, but it should be really close.\n",
    "print(\"Average for entire dataset: \", np.mean(scores_entire, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posture - Accuracy: 0.9818977521384523\n",
      "BicepCurls - Accuracy: 0.9364608076009501\n",
      "SideLunges - Accuracy: 0.8609668397922493\n",
      "Sitting - Accuracy: 0.9841784989858012\n",
      "Squats - Accuracy: 0.8677669516802545\n",
      "Standing - Accuracy: 0.9658865529551766\n",
      "Average for testing dataset:  0.9328595671921475\n"
     ]
    }
   ],
   "source": [
    "# Scoring indivdual actions for the testing dataset\n",
    "\n",
    "actions = frame['y'].unique()\n",
    "scores_testing = []\n",
    "\n",
    "for action in actions:\n",
    "    # Get y testing data\n",
    "    y_frame = pd.DataFrame(le.inverse_transform(y_test))\n",
    "    # Select only the wanted action for scoring\n",
    "    y_string = y_frame.where(y_frame == action).dropna()\n",
    "    # Get X testing data from the corresponding y indecies\n",
    "    X_data = X_test[y_string.index]\n",
    "    # Convert the y data back to numeric classes\n",
    "    y_data = le.transform(y_string.to_numpy().ravel())\n",
    "    # Reset y index (not needed currently)\n",
    "    # y_data = y_data.reset_index(drop=True)\n",
    "    \n",
    "    accuracy = clf_rfc.score(X_data, y_data)\n",
    "    scores_testing.append(accuracy)\n",
    "    print(action +\" - \"+ \"Accuracy:\", accuracy)\n",
    "\n",
    "# Not quite and exact average because different actions may have more data points, but it should be really close.\n",
    "print(\"Average for testing dataset: \", np.mean(scores_testing, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTreeClassifier() \n",
      "Accuracy: 0.8654581673306773 \n",
      "Recall: 0.8827407774427171 \n",
      "Precision: 0.880705116506292\n"
     ]
    }
   ],
   "source": [
    "# Function abstraction\n",
    "train_new_model(r'C:\\Users\\conno\\Desktop\\Pastebles\\data', DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: ['Squats'] \n",
      "Actual: ['SideLunges']\n"
     ]
    }
   ],
   "source": [
    "# Manually testing individual points\n",
    "\n",
    "index = 102\n",
    "x_pred = frame.drop(['arrival_time', \"y\"],axis=1).iloc[index].to_numpy().reshape(1,-1)\n",
    "x_pred = X_test[index].reshape(1, -1)\n",
    "y_pred = y_test[index].ravel()\n",
    "\n",
    "out = clf_rfc.predict(x_pred)\n",
    "# list(le.inverse_transform(out))\n",
    "# list(le.inverse_transform(y_test[0].ravel()))\n",
    "\n",
    "print(\"Predicted:\", le.inverse_transform(out), \"\\nActual:\",le.inverse_transform(y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
